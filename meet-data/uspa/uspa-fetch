#!/usr/bin/env python3
# vim: set ts=8 sts=4 et sw=4 tw=99:
#
# Parse the USPA competition results download page and download
# any that aren't in the USPA meet results.
#


from bs4 import BeautifulSoup
import os
import shutil
import sys
import urllib.request


CUTOFF = 300 # Ignore earlier meets, since they'll be in random formats.
FETCHDIR = 'fetch-tmp' # Directory in CWD to use for fetchin'.
RESULTSURL = 'https://docs.google.com/spreadsheets/d/1HBpedvVS8N0H75Eg9qwTxClqtV1EqO-IuctYzgiyMNI/pubhtml/sheet?hl=en_US&headers=false&gid=0'


# Just a way to name a tuple.
class Meet:
    def __init__(self, url, num, date, name, location):
        self.url = url
        self.num = ("0" * (4 - len(num))) + num
        self.date = date
        self.name = name
        self.location = location

    def __str__(self):
        return '"%s - %s %s %s"' % (self.num, self.date, self.name, self.location)

    def __repr__(self):
        return str(self)


def gethtml():
    with urllib.request.urlopen(RESULTSURL) as r:
        return r.read()


def getmeetinfo(tr):
    # Meets that have information have a URL in a td of class s3.
    urltd = tr.find('td', {'class':'s3'})
    if urltd == None:
        return None

    a = urltd.find('a')
    if a == None:
        return None
    url = a.get('href')

    # Then the rest of the information should be there too.
    tds = tr.find_all('td')
    num = tds[1].get_text()
    date = tds[2].get_text()
    name = tds[3].get_text()
    location = tds[4].get_text()

    return Meet(url, num, date, name, location)


def getmeetlist(html):
    soup = BeautifulSoup(html, 'html.parser')

    # Ignore all the Google Sheets javascript and get to the tags.
    doc = soup.find(id='sheets-viewport')
    table = doc.find('table')

    meets = []

    # Iterate over every row of the table.
    for tr in table.find_all('tr'):
        info = getmeetinfo(tr)
        if info:
            meets.append(info)

    return meets


def getknownmeets():
    # Known meets for the USPA have numeric directory names.
    meets = []
    for name in os.listdir(os.getcwd()):
        if name.isdigit():
            meets.append(name)
    return meets


def getunknownmeets(meets, known):
    unknown = []
    for meet in meets:
        if meet.num not in known and int(meet.num) >= CUTOFF:
            unknown.append(meet)
    return unknown


# The meet URL is actually a URL with a link to the actual URL!
def getpdfurl(meet):
    with urllib.request.urlopen(meet.url) as r:
        soup = BeautifulSoup(r.read(), 'html.parser')

    body = soup.body.get_text()
    url = body[body.index('http'):]
    return url


def downloadpdf(meet):
    pdfurl = getpdfurl(meet)

    filename = FETCHDIR + os.sep + meet.num + '.pdf'
    with urllib.request.urlopen(pdfurl) as r, open(filename, 'wb') as fd:
        shutil.copyfileobj(r, fd)


def main():
    html = gethtml()
    meets = getmeetlist(html)
    known = getknownmeets()
    remote = getunknownmeets(meets, known)

    for meet in remote:
        print('Fetching %s' % meet.num)
        downloadpdf(meet)


if __name__ == '__main__':
    # Make reasonable assertions that the cwd is the USPA results directory.
    if os.getcwd().split(os.sep)[-1] != 'uspa' or not os.path.isfile('UPDATING'):
        print(" %s must be run from the USPA meet data directory." % sys.argv[0])
        sys.exit(1)

    if not os.path.exists(FETCHDIR):
        os.makedirs(FETCHDIR)

    main()
